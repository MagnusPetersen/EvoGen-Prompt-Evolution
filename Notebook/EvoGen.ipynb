{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/main/diffusers/stable_diffusion_fast_jax.ipynb","timestamp":1666388861522}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5e33f27ec16f41b9acbfcc89611e45be":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_c9ef6c674ab746e8828721c5098aa609","IPY_MODEL_fc6af13fa15b4b248547af554fc6db81","IPY_MODEL_9bb8a4d910384a8ea21dd2919cb9995d","IPY_MODEL_3fa878c67545432cae869894f98b7ab7"],"layout":"IPY_MODEL_6b3136e2034845d6bcc4d0ed64d5ead1"}},"c9ef6c674ab746e8828721c5098aa609":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ff40fe51ecc4c68a2abe0d4f7986851","placeholder":"â€‹","style":"IPY_MODEL_ae1a15adbcd846cd8b664dbdbf8b056c","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"fc6af13fa15b4b248547af554fc6db81":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_063e0e818e684523920bf261ad1c2523","placeholder":"â€‹","style":"IPY_MODEL_7f2b761154ef4c1ea98183321b6b6ba6","value":""}},"9bb8a4d910384a8ea21dd2919cb9995d":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_a2327fee77f747abaab14a547e184a3f","style":"IPY_MODEL_2c3655de21a94ffb85c7284a1dd81f3a","tooltip":""}},"3fa878c67545432cae869894f98b7ab7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63fe771d96ec40498cf75e4b29231935","placeholder":"â€‹","style":"IPY_MODEL_8f14a14399674685b92b412a3de6d3d3","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"6b3136e2034845d6bcc4d0ed64d5ead1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"0ff40fe51ecc4c68a2abe0d4f7986851":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae1a15adbcd846cd8b664dbdbf8b056c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"063e0e818e684523920bf261ad1c2523":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f2b761154ef4c1ea98183321b6b6ba6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2327fee77f747abaab14a547e184a3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c3655de21a94ffb85c7284a1dd81f3a":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"63fe771d96ec40498cf75e4b29231935":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f14a14399674685b92b412a3de6d3d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **Evolutionary Prompt-Mining Jax**\n","[Stable Diffusion](https://github.com/CompVis/stable-diffusion) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, BjÃ¶rn Ommer and the [Stability.ai](https://stability.ai/) Team. [K Diffusion](https://github.com/crowsonkb/k-diffusion) by [Katherine Crowson](https://twitter.com/RiversHaveWings). You need to get the ckpt file and put it on your Google Drive first to use this. It can be downloaded from [HuggingFace](https://huggingface.co/CompVis/stable-diffusion).\n","\n","The aesthetics model that is an integral part of this method was made by [Katherine Crowson](https://twitter.com/RiversHaveWings) and can be found on her [Github account](https://github.com/crowsonkb/simulacra-aesthetic-models). Some parts of the CLIP guidance is also by her.\n","\n","Notebook by [Magnus Petersen](https://twitter.com/Omorfiamorphism), the baseline of the notebook, setup, description, and image generation, is based on the\n","[deforum](https://discord.gg/upmXXsrwZc) notebook and the [Stable Diffusion with Jax](https://huggingface.co/blog/stable_diffusion_jax) code. "],"metadata":{"id":"KkczoRRE8XZw"}},{"cell_type":"code","source":["#@title Install required libraries\n","from IPython.display import clear_output, display\n","!pip install huggingface_hub==0.10.0 gradio\n","clear_output()"],"metadata":{"id":"0YHLndloz1U_","cellView":"form","executionInfo":{"status":"ok","timestamp":1666888685285,"user_tz":-120,"elapsed":18253,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#@title Login to the Hugging Face Hub\n","#@markdown Make sure you also have read and accept the LICENSE of the [Stable Diffusion model](https://huggingface.co/runwayml/stable-diffusion-v1-5), otherwise you may find an error\n","from huggingface_hub import notebook_login\n","!git config --global credential.helper store\n","\n","notebook_login()"],"metadata":{"id":"e5Ew5kcf0H05","executionInfo":{"status":"ok","timestamp":1666888686298,"user_tz":-120,"elapsed":762,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}},"outputId":"6f32fc7b-4843-4003-c289-8c38d59ef1e8","colab":{"base_uri":"https://localhost:8080/","height":271,"referenced_widgets":["5e33f27ec16f41b9acbfcc89611e45be","c9ef6c674ab746e8828721c5098aa609","fc6af13fa15b4b248547af554fc6db81","9bb8a4d910384a8ea21dd2919cb9995d","3fa878c67545432cae869894f98b7ab7","6b3136e2034845d6bcc4d0ed64d5ead1","0ff40fe51ecc4c68a2abe0d4f7986851","ae1a15adbcd846cd8b664dbdbf8b056c","063e0e818e684523920bf261ad1c2523","7f2b761154ef4c1ea98183321b6b6ba6","a2327fee77f747abaab14a547e184a3f","2c3655de21a94ffb85c7284a1dd81f3a","63fe771d96ec40498cf75e4b29231935","8f14a14399674685b92b412a3de6d3d3"]},"cellView":"form"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Login successful\n","Your token has been saved to /root/.huggingface/token\n"]}]},{"cell_type":"code","source":["#@markdown **Model and Output Paths**\n","# ask for the link\n","print(\"Local Path Variables:\\n\")\n","\n","output_path = \"/content/output\" #@param {type:\"string\"}\n","\n","#@markdown **Google Drive Path Variables (Optional)**\n","mount_google_drive = True #@param {type:\"boolean\"}\n","force_remount = False\n","\n","if mount_google_drive:\n","    from google.colab import drive # type: ignore\n","    try:\n","        drive_path = \"/content/drive\"\n","        drive.mount(drive_path,force_remount=force_remount)\n","        output_path_gdrive = \"/content/drive/MyDrive/AI/StableDiffusion\" #@param {type:\"string\"}\n","        output_path = output_path_gdrive\n","    except:\n","        print(\"...error mounting drive or with drive path variables\")\n","        print(\"...reverting to default path variables\")\n","\n","import os\n","import time\n","os.makedirs(output_path, exist_ok=True)\n","\n","def get_output_folder(output_path, batch_folder):\n","    out_path = os.path.join(output_path,time.strftime('%Y-%m'))\n","    if batch_folder != \"\":\n","        out_path = os.path.join(out_path, batch_folder)\n","    os.makedirs(out_path, exist_ok=True)\n","    return out_path\n","\n","print(f\"output_path: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"GeLWOpZ0w7bU","executionInfo":{"status":"ok","timestamp":1666888713202,"user_tz":-120,"elapsed":16255,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}},"outputId":"215fdcda-2fb1-4a82-8922-e74e04885da8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Local Path Variables:\n","\n","Mounted at /content/drive\n","output_path: /content/drive/MyDrive/AI/StableDiffusion\n"]}]},{"cell_type":"code","source":["#@title Set up JAX\n","#@markdown If you see an error, make sure you are using a TPU backend. Select `Runtime` in the menu above, then select the option \"Change runtime type\" and then select `TPU` under the `Hardware accelerator` setting.\n","!pip install --upgrade jax jaxlib \n","\n","import jax.tools.colab_tpu\n","jax.tools.colab_tpu.setup_tpu('tpu_driver_20221011')\n","\n","!pip install flax diffusers transformers ftfy\n","clear_output()\n","jax.devices()"],"metadata":{"id":"5Dz5aeq_yUNq","cellView":"form","executionInfo":{"status":"ok","timestamp":1666888770139,"user_tz":-120,"elapsed":56948,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}},"outputId":"8bfa4959-2187-4444-febe-3b960a29d300","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n"," TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n"," TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n"," TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n"," TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n"," TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n"," TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n"," TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#@title Import required libraries\n","import numpy as np\n","import jax\n","import jax.numpy as jnp\n","\n","from pathlib import Path\n","from jax import pmap\n","from flax.jax_utils import replicate\n","from flax.training.common_utils import shard\n","from PIL import Image\n","\n","from huggingface_hub import notebook_login\n","from diffusers import FlaxStableDiffusionPipeline\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as T\n","import torchvision.transforms.functional as TF\n","import pandas as pd\n","import os\n","import gc\n","import random\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","! git clone https://github.com/MagnusPetersen/EvoGen-Prompt-Evolution.git\n","\n","def image_grid(imgs, rows, cols):\n","    w,h = imgs[0].size\n","    grid = Image.new('RGB', size=(cols*w, rows*h))\n","    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))\n","    return grid"],"metadata":{"id":"UFMtdmPeyxpi","cellView":"form","executionInfo":{"status":"ok","timestamp":1666888780723,"user_tz":-120,"elapsed":10604,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d146c6b-3390-4aed-9c05-6facd5f44f75"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'EvoGen-Prompt-Evolution'...\n","remote: Enumerating objects: 128, done.\u001b[K\n","remote: Counting objects: 100% (128/128), done.\u001b[K\n","remote: Compressing objects: 100% (89/89), done.\u001b[K\n","remote: Total 128 (delta 41), reused 113 (delta 29), pack-reused 0\u001b[K\n","Receiving objects: 100% (128/128), 8.63 MiB | 10.34 MiB/s, done.\n","Resolving deltas: 100% (41/41), done.\n"]}]},{"cell_type":"code","source":["#@title Load the model\n","#@markdown It's safe to ignore the warning messages, everything is okay\n","pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", revision=\"bf16\", dtype=jnp.bfloat16)\n","p_params = replicate(params)\n","clear_output()"],"metadata":{"id":"PPtraQX34Az7","cellView":"form","executionInfo":{"status":"ok","timestamp":1666889029231,"user_tz":-120,"elapsed":248522,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#@title Aesthetics Helpers\n","\n","from torchvision.transforms import functional as TF\n","import torch.nn.functional as F\n","\n","!git clone https://github.com/openai/CLIP\n","!git clone https://github.com/crowsonkb/simulacra-aesthetic-models\n","!pip install -e ./CLIP\n","import sys\n","sys.path.append('./CLIP')\n","\n","import clip\n","from torchvision import transforms\n","import matplotlib.pyplot as plt \n","\n","class AestheticMeanPredictionLinearModel(nn.Module):\n","    def __init__(self, feats_in):\n","        super().__init__()\n","        self.linear = nn.Linear(feats_in, 1)\n","\n","    def forward(self, input):\n","        x = F.normalize(input, dim=-1) * input.shape[-1] ** 0.5\n","        return self.linear(x)\n","\n","clip_model_name = 'ViT-B/16'\n","clip_model = clip.load(clip_model_name, jit=False, device=device)[0]\n","clip_model.eval().requires_grad_(False)\n","\n","normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n","                                 std=[0.26862954, 0.26130258, 0.27577711])\n","\n","# 512 is embed dimension for ViT-B/16 CLIP\n","aes_model = AestheticMeanPredictionLinearModel(512)\n","aes_model.load_state_dict(\n","    torch.load(\"/content/simulacra-aesthetic-models/models/sac_public_2022_06_29_vit_b_16_linear.pth\")\n",")\n","\n","aes_model = aes_model.to(device)\n","\n","artists = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/artists.csv').dropna()\n","genres = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/genres.csv').dropna()\n","words = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/wordlist.csv').dropna()\n","words_aes = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/wordsprompt.csv').dropna()\n","engrams_aes = pd.read_csv('/content/EvoGen-Prompt-Evolution/Wordlists/engramprompt.csv').dropna()\n","\n","\n","clear_output()"],"metadata":{"id":"i96IDgRC4Sqt","cellView":"form","executionInfo":{"status":"ok","timestamp":1666889061331,"user_tz":-120,"elapsed":32112,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#@title Evolution Helpers\n","\n","class PromptGenerator:\n","    def __init__(self, population_count, prompt_length_max, prompt_length_min,\n","                 artist_prop, genre_prop, custom_prop, delete_prop, add_prop, mutate_prop,\n","                 shuffle_prop, cross_prop, k):\n","        self.artists = artists\n","        self.genres = genres\n","        if use_aes_words:\n","          self.words = words_aes\n","        if use_aes_engrams:\n","          self.words = engrams_aes\n","        if use_aes_words and use_aes_engrams:\n","          self.words = words_aes.append(engrams_aes)\n","        if use_aes_words == False and use_aes_engrams == False:\n","          self.words = words\n","\n","        self.custom = custom\n","        self.population_count = population_count\n","        self.prompt_length_max = prompt_length_max \n","        self.prompt_length_min = prompt_length_min\n","\n","        self.artist_prop = artist_prop \n","        self.genre_prop = genre_prop \n","        self.custom_prop = custom_prop\n","\n","        self.word_prop = 1 - self.artist_prop - self.genre_prop\n","        self.delete_prop = delete_prop \n","        self.add_prop = add_prop \n","        \n","        self.mutate_prop = mutate_prop \n","        self.shuffle_prop = shuffle_prop \n","        self.cross_prop = cross_prop \n","        self.k = k \n","\n","        self.fittness_history = []\n","\n","    def initialize_prompt_population(self):\n","        #initialize the prompt population by randomly selecting words from artists, genres, and words dictionaries\n","        prompt_population = []\n","        for i in range(self.population_count):\n","            prompt = []\n","            for j in range(np.random.randint(self.prompt_length_min, self.prompt_length_max)):\n","                #pic based on artist_prop, genre_prop, and word_prop probabilities which dataframe to select from\n","                rand_num = np.random.random()\n","                if rand_num < self.artist_prop:\n","                    prompt.append(self.artists.sample(1).artist.values[0])\n","                elif rand_num < self.artist_prop + self.genre_prop:\n","                    prompt.append(self.genres.sample(1).genre.values[0])\n","                elif rand_num < self.artist_prop + self.genre_prop + self.custom_prop:\n","                    prompt.append(self.custom.sample(1).custom.values[0])\n","                else:\n","                    prompt.append(self.words.sample(1).word.values[0])\n","            prompt_population.append(prompt)\n","        self.prompt_population = prompt_population\n","\n","    def selection(self, scores):\n","        selection_ix = np.random.randint(self.population_count)\n","        for ix in np.random.randint(0, self.population_count, self.k-1):\n","            if scores[ix] > scores[selection_ix]:\n","                selection_ix = ix\n","        return self.prompt_population[selection_ix]\n","\n","    def cross_over(self, prompt_1, prompt_2):\n","        c1, c2 = prompt_1, prompt_2\n","        rand_num = np.random.random()\n","        if rand_num < self.cross_prop:\n","            if len(prompt_2) ==0:\n","              prompt_index = 0\n","            else:\n","              prompt_index = np.random.randint(0, min(len(prompt_1), len(prompt_2)))\n","            c1 = prompt_1[:prompt_index] + prompt_2[prompt_index:]\n","            c2 = prompt_2[:prompt_index] + prompt_1[prompt_index:]\n","        return [c1, c2]\n","\n","    def mutate_prompts(self, prompt):\n","        if (len(prompt) == 0):\n","          prompt_index = 0\n","          rand_num = np.random.random()\n","          if rand_num < self.artist_prop:\n","              prompt.insert(prompt_index, self.artists.sample(1).artist.values[0])\n","          elif rand_num < self.artist_prop + self.genre_prop:\n","              prompt.insert(prompt_index, self.genres.sample(1).genre.values[0])\n","          elif rand_num < self.artist_prop + self.genre_prop + self.custom_prop:\n","              prompt.insert(prompt_index, self.custom.sample(1).custom.values[0])\n","          else:\n","              prompt.insert(prompt_index, self.words.sample(1).word.values[0])\n","\n","        for i in range(len(prompt)):\n","            rand_num = np.random.random()\n","            if rand_num < self.mutate_prop:\n","                rand_num = np.random.random()\n","                if rand_num < self.artist_prop:\n","                    prompt[i] = self.artists.sample(1).artist.values[0]\n","                elif rand_num < self.artist_prop + self.genre_prop:\n","                    prompt[i] = self.genres.sample(1).genre.values[0]\n","                elif rand_num < self.artist_prop + self.genre_prop + self.custom_prop:\n","                    prompt[i] = self.custom.sample(1).custom.values[0]\n","                else:\n","                    prompt[i] = self.words.sample(1).word.values[0]\n","\n","\n","        delete_count = np.random.binomial(len(prompt), self.delete_prop)\n","        if len(prompt) - delete_count < 2:\n","            delete_count = len(prompt) - 2\n","\n","        prompt = np.delete(prompt, np.random.randint(len(prompt), size=delete_count)).tolist()\n","        \n","        for i in range(len(prompt)):\n","            rand_num = np.random.random()\n","            if rand_num < self.add_prop:\n","                rand_num = np.random.random()\n","                if rand_num < self.artist_prop:\n","                    prompt.insert(i, self.artists.sample(1).artist.values[0])\n","                elif rand_num < self.artist_prop + self.genre_prop:\n","                    prompt.insert(i, self.genres.sample(1).genre.values[0])\n","                elif rand_num < self.artist_prop + self.genre_prop + self.custom_prop:\n","                    prompt.insert(i, self.custom.sample(1).custom.values[0])\n","                else:\n","                    prompt.insert(i, self.words.sample(1).word.values[0])\n","            \n","        rand_num = np.random.random()\n","        if rand_num < self.shuffle_prop:\n","            prompt = np.random.permutation(prompt).tolist()\n","            \n","        return prompt\n","\n","    def create_next_generation(self, scores):\n","        selected = [self.selection(scores) for _ in range(self.population_count)]\n","        children = []\n","        for i in range(0, self.population_count, 2):\n","            prompt_1, prompt_2 = selected[i], selected[i+1]\n","            for c in self.cross_over(prompt_1, prompt_2):\n","                c = self.mutate_prompts(c)\n","                children.append(c)\n","\n","        filtered_children = []\n","        for elem in children:\n","            if elem not in filtered_children:\n","                filtered_children.append(elem)\n","\n","        children = filtered_children\n","\n","        missing_prompts = self.population_count - len(children)\n","        print(\"The following number of duplicate prompts had to be replaced with random ones:\"+str(missing_prompts))\n","        for i in range(missing_prompts):\n","            prompt = []\n","            for j in range(np.random.randint(self.prompt_length_min, self.prompt_length_max)):\n","                rand_num = np.random.random()\n","                if rand_num < self.artist_prop:\n","                    prompt.append(self.artists.sample(1).artist.values[0])\n","                elif rand_num < self.artist_prop + self.genre_prop:\n","                    prompt.append(self.genres.sample(1).genre.values[0])\n","                else:\n","                    prompt.append(self.words.sample(1).word.values[0])\n","            children.append(prompt)\n","\n","        self.prompt_population = children\n","\n","    def population_as_string(self):\n","        return [' '.join(prompt) for prompt in self.prompt_population]"],"metadata":{"cellView":"form","id":"HV9Y1gothcJQ","executionInfo":{"status":"ok","timestamp":1666889061331,"user_tz":-120,"elapsed":13,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["custom_words = [\"ðŸ˜€\", \"ðŸ˜ƒ\", \"ðŸ˜„\", \"ðŸ˜\", \"ðŸ˜†\", \"ðŸ˜…\", \"ðŸ˜‚\", \"ðŸ¤£\", \"ðŸ¥²\", \"â˜ºï¸\", \"ðŸ˜Š\", \"ðŸ˜‡\", \"ðŸ™‚\", \"ðŸ™ƒ\", \"ðŸ˜‰\", \"ðŸ˜Œ\", \"ðŸ˜\", \"ðŸ¥°\", \"ðŸ˜˜\", \"ðŸ˜—\"]\n","custom = pd.DataFrame(custom_words, columns=[\"custom\"])"],"metadata":{"id":"-WjGakJqhlIj","executionInfo":{"status":"ok","timestamp":1666889061331,"user_tz":-120,"elapsed":12,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#@markdown **Evolutionary Algorithm Settings**\n","\n","#@markdown General population settings, such as how many generations the algorithm runs for, how many prompts there are in each generation, and the word length range of the prompts.\n","generations = 25 #@param\n","n_samples = 8\n","population_count = 400 #@param\n","population_count = int(n_samples*(population_count//n_samples + 1))\n","prompt_length_max = 15 #@param\n","prompt_length_min = 3 #@param\n","#@markdown Probability to sample from one of the word lists when adding or mutating a word. The difference between the sum of the three custom lists and 1 is the probability to sample from the English dictionary word list.\n","artist_prop = 0.04 #@param\n","genre_prop = 0.08 #@param\n","custom_prop = 0.0 #@param\n","#@markdown Decide which list to use if the genre, custom and artists list are not selected from sampling. Use either a list from high scoring prompts, 2/3-grams of those prompts of both. If none are selected use a complete english dictionary.\n","use_aes_words = False #@param {type:\"boolean\"}\n","use_aes_engrams = False #@param {type:\"boolean\"}\n","#@markdown Generation evolution settings including the probability to delete, add and swap out each word for a new one from the dictionary.\n","delete_prop = 0.2 #@param\n","add_prop = 0.21 #@param\n","mutate_prop = 0.3 #@param\n","shuffle_prop = 0.1 #@param\n","#@markdown Generation evolution settings for the new generation parent selection and breeding. The cross-over probability is the probability of the parents swapping prompt parts. K denotes the rounds in the tournament selection process. A higher K value means fewer parents generate the next generation, this means a higher score increase but less diversity in the prompts.\n","cross_prop = 0.8 #@param\n","k = 4 #@param\n","#@markdown Cutoff score to save the image and prompt\n","cutoff = 6.0 #@param\n","#@markdown True if you want to guide the evolution with an aditional prompt and not just aesthetics\n","use_prompt = False #@param {type:\"boolean\"}\n","prompt = \"ultra detailed beautiful female android, side portrait, sharp focus, highly detailed vfx portrait, scribble art, geometric shapes, global illumination, by james jean and moebius and artgerm and liam brazier and victo ngai and tristan eaton. vector art, digital illustration, concept art, dia de los muertos. 8 k, hdr \" #@param {type:\"string\"}\n","prompt_weigth = 0.5 #@param\n","encoding = clip_model.encode_text(clip.tokenize(prompt).to(device)).float()\n","#@markdown **Save & Display Settings**\n","batch_name = \"StableEvo\" #@param {type:\"string\"}\n","outdir = get_output_folder(output_path, batch_name)\n","save_samples = False #@param {type:\"boolean\"}\n","display_samples = False #@param {type:\"boolean\"}\n","\n","#@markdown **Image Settings**\n","W = 512 #@param\n","H = 512 #@param\n","W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n","\n","#@markdown **Sampling Settings**\n","num_inference_steps = 25 #@param {type:\"integer\"}\n","seed = -1 #@param {type:\"integer\"}\n","#@markdown `-1` will set a random seed. You can replace that to any integer for reproducible results\n","\n","def filtered_with_scores(special_cos_dist, cos_dist, images, safety_model_params):\n","  return images, [False]\n","pipeline.safety_checker.filtered_with_scores = filtered_with_scores\n","\n","n_samples = jax.device_count()\n","\n","prompt_generator = PromptGenerator(population_count, prompt_length_max, prompt_length_min,\n","                                  artist_prop, genre_prop, custom_prop, delete_prop, add_prop, mutate_prop,\n","                                  shuffle_prop, cross_prop, k)\n","prompt_generator.initialize_prompt_population()\n","\n","mean_score = []\n","mean_loss_prompt = []\n","best_score = []\n","mean_prompt_length = []"],"metadata":{"id":"g4LUKd5vhl9X","executionInfo":{"status":"ok","timestamp":1666896201334,"user_tz":-120,"elapsed":54995,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}},"cellView":"form"},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["#@title Evolution Loop\n","\n","def plot_fittness_history():\n","  plt.figure(figsize=(14,7))\n","  plt.rcParams.update({'font.size': 12})\n","  plt.subplot(2,2,1)\n","  plt.plot(mean_score)\n","  plt.title(\"Mean Score\")\n","  plt.xlabel(\"Generation\")\n","  plt.ylabel(\"Score\")\n","  plt.subplot(2,2,2)\n","  plt.plot(best_score)\n","  plt.title(\"Best Score\")\n","  plt.xlabel(\"Generation\")\n","  plt.ylabel(\"Score\")\n","  plt.subplot(2,2,3)\n","  plt.hist(scores[::, 0], bins=20)\n","  plt.title(\"Score Histogram\")\n","  plt.xlabel(\"Score\")\n","  plt.ylabel(\"Frequency\")\n","  plt.subplot(2,2,4)\n","  plt.plot(mean_prompt_length)\n","  plt.title(\"Mean Prompt Length\")\n","  plt.xlabel(\"Generation\")\n","  plt.ylabel(\"Prompt Length\")\n","  plt.tight_layout()\n","  if use_prompt:\n","    plt.figure(figsize=(14,3))\n","    plt.rcParams.update({'font.size': 12})\n","    plt.subplot(1,1,1)\n","    #plot the mean prompt score over time\n","    plt.plot(mean_loss_prompt)\n","    plt.title(\"Prompt Loss\")\n","    plt.xlabel(\"Generation\")\n","    plt.ylabel(\"Loss\")\n","    plt.tight_layout()\n","  plt.figure(figsize=(14,7))\n","  plt.rcParams.update({'font.size': 12})\n","  plt.subplot(1,1,1)\n","  plt.bar(most_frequent_words.word, most_frequent_words.frequency)\n","  plt.xticks(rotation=90)\n","  plt.title(\"Most Frequent Words\")\n","  plt.xlabel(\"Word\")\n","  plt.ylabel(\"Count\")\n","  plt.tight_layout()\n","  plt.show()\n","\n","def plot_top_9():\n","  top_9idx = torch.flip(np.argsort(scores)[-9:], (0,)).tolist()\n","  print(*[prompts[i] for i in top_9idx], sep = \"\\n\")\n","  with open(os.path.join(gen_path, \"best_9_prompts.txt\"), 'w') as f:\n","    f.write('\\n'.join([prompts[i] for i in top_9idx]))\n","  top_9 = image_population[top_9idx]\n","  top_9 = torch.cat([top_9[i:i+3] for i in range(0, 9, 3)], dim=2)\n","  top_9 = torch.cat([top_9[i:i+1] for i in range(0, 3, 1)], dim=3)\n","  best_img = transforms.ToPILImage()(top_9[0])\n","  display(best_img)\n","  best_img.save(os.path.join(gen_path, \"best_9.png\"))\n","\n","def shard_and_gen_images(prompts):\n","  if(seed == -1):\n","    random_int = random.randint(0, 2147483647)\n","    real_seed = random_int\n","  else:\n","    real_seed = seed\n","  prng_seed = jax.random.PRNGKey(real_seed)\n","  prng_seed = jax.random.split(prng_seed, jax.device_count())\n","  prompt_ids = pipeline.prepare_inputs(prompts)\n","  prompt_ids = shard(prompt_ids)\n","  images = pipeline(prompt_ids, p_params, prng_seed, num_inference_steps, jit=True, height = H, width = W).images\n","  return images, real_seed\n","\n","def spherical_dist_loss(x, y):\n","    x = F.normalize(x, dim=-1)\n","    y = F.normalize(y, dim=-1)\n","    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n","\n","def fittness_function(images):\n","  clip_preped_images = torch.zeros(size = (n_samples, 3, 224, 224))\n","  for i in range(len(images)):\n","    img = TF.resize(images[i], 224, transforms.InterpolationMode.LANCZOS)\n","    img = TF.center_crop(img, (224,224))\n","    img = TF.to_tensor(img).to(device)\n","    img = normalize(img)\n","    clip_preped_images[i] = img\n","\n","  clip_image_embed = F.normalize(\n","      clip_model.encode_image(clip_preped_images.to(device)).float(),\n","      dim=-1)\n","  scores = aes_model(clip_image_embed).mean(axis = 1)\n","  if use_prompt:\n","    dists = spherical_dist_loss(clip_image_embed.unsqueeze(1), encoding.unsqueeze(0))\n","    dists = dists.view([1, n_samples, -1])\n","    prompt_score = dists.sum(2).mean(0)\n","  else:\n","    prompt_score = torch.zeros(size =(1,))\n","  return scores, prompt_score\n","\n","with torch.no_grad():\n","  for i in range(generations):\n","    gen_path = get_output_folder(output_path, batch_name)+'/gen_'+str(i)\n","    os.makedirs(gen_path, exist_ok=True)\n","    os.makedirs(gen_path+\"/best\", exist_ok=True)\n","  \n","    prompts = prompt_generator.population_as_string()\n","    image_population = torch.zeros(size = (prompt_generator.population_count, 3, H, W))\n","    scores = torch.zeros(prompt_generator.population_count, 2)\n","    displayed_img_count = 0\n","\n","    for j in range(0, prompt_generator.population_count, n_samples):\n","      gc.collect()\n","      torch.cuda.empty_cache()\n","\n","      images, current_seed = shard_and_gen_images(prompts[j:(j+n_samples)])\n","      images_pil = pipeline.numpy_to_pil(np.asarray(images.reshape((n_samples,) + images.shape[-3:])))\n","      aes_score, prompt_score = fittness_function(images_pil)\n","      scores[j:(j+n_samples), 0] = aes_score\n","      scores[j:(j+n_samples), 1] = prompt_score\n","\n","      for k in range(len(images)):\n","        image_population[j+k] = torch.tensor(np.float32(images[k]))[0].permute([2, 0, 1])\n","\n","        if display_samples:\n","          print(prompts[j+k])\n","          display(images_pil[k])\n","          displayed_img_count += 1\n","          if displayed_img_count >= 32:\n","              clear_output(wait=True)\n","              displayed_img_count = 0\n","      \n","        if save_samples:\n","            filename = prompts[j+k]+\".png\"\n","            images_pil[k].save(os.path.join(gen_path, filename))\n","\n","        if scores[j+k, 0] >= cutoff:\n","          filename_length = min(150, len(prompts[j+k]))\n","          images_pil[k].save(gen_path+'/best/'+prompts[j+k][:filename_length]+'.png')\n","          with open(gen_path+'/best/'+prompts[j+k][:filename_length]+'.txt', 'w') as f:\n","            f.write(prompts[j+k])\n","            f.write('\\n')\n","            f.write(str(current_seed))\n","          if save_samples == False:\n","            print(prompts[j+k])\n","            display(images_pil[k])\n","            displayed_img_count += 1\n","            if displayed_img_count >= 32:\n","              clear_output(wait=True)\n","              displayed_img_count = 0\n","\n","    clear_output(wait=True)\n","    mean_score.append(scores[::, 0].mean().item())\n","    mean_loss_prompt.append(scores[::, 1].mean().item())\n","    best_score.append(max(scores[::, 0]).item())\n","    mean_prompt_length.append(np.mean([len(prompt) for prompt in prompt_generator.prompt_population]))\n","    most_frequent_words = pd.DataFrame(sum(prompt_generator.prompt_population, []), columns = ['word']).word.value_counts().head(20).reset_index()\n","    most_frequent_words.columns = ['word', 'frequency']\n","\n","    plot_fittness_history()\n","    if use_prompt:\n","      scores[::, 0] = (scores[::, 0] - scores[::, 0].min()) / (scores[::, 0].max() - scores[::, 0].min())\n","      scores[::, 1] = torch.abs((scores[::, 1] - scores[::, 1].min()) / (scores[::, 1].max() - scores[::, 1].min()) - 1)\n","      scores = prompt_weigth*scores[::, 0] + (1-prompt_weigth)*scores[::, 1]\n","    else:\n","      scores = scores[::, 0]\n","    plot_top_9()\n","\n","    prompt_generator.create_next_generation(scores)"],"metadata":{"id":"WxO5p4NPhqsp","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Generate in higher Quality\n","Changing setting causes longer runtimes for the first time with those setting in the Jax version"],"metadata":{"id":"cz9Q3GqoqlvC"}},{"cell_type":"code","source":["prompts = [\n","    \"rebraced dadoed sealkie irritative abanga Street art behaviored deacons Gino Severini\",\n","]\n","prompts = prompts*n_samples\n","\n","seed = -1\n","inference_steps = 50\n","height = 700\n","width = 700"],"metadata":{"id":"3tZ4ydDVqohF","executionInfo":{"status":"ok","timestamp":1666895891453,"user_tz":-120,"elapsed":254,"user":{"displayName":"M Petersen","userId":"13637530209006951077"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["#@title Inference\n","\n","width, height = map(lambda x: x - x % 64, (width, height))  # resize to integer multiple of 64\n","\n","def gen_images(prompts, width, height, inference_steps, seed):\n","  if(seed == -1):\n","    random_int = random.randint(0, 2147483647)\n","    real_seed = random_int\n","  else:\n","    real_seed = seed\n","  prng_seed = jax.random.PRNGKey(real_seed)\n","  prng_seed = jax.random.split(prng_seed, jax.device_count())\n","  prompt_ids = pipeline.prepare_inputs(prompts)\n","  prompt_ids = shard(prompt_ids)\n","  images = pipeline(prompt_ids, p_params, prng_seed, num_inference_steps=inference_steps, jit=True, height = height, width = width).images\n","  images_pil = pipeline.numpy_to_pil(np.asarray(images.reshape((n_samples,) + images.shape[-3:])))\n","  return images_pil\n","\n","images = gen_images(prompts, width, height, inference_steps, seed)\n","\n","for i in range(len(images)):\n","  display(images[i])"],"metadata":{"cellView":"form","id":"GKPCfVV4rI6W"},"execution_count":null,"outputs":[]}]}